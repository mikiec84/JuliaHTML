{
 "metadata": {
  "language": "Julia",
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import RDatasets\n",
      "import DataFrames\n",
      "import Clustering\n",
      "import SVM\n",
      "import DecisionTree"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 112
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# read data\n",
      "iris = RDatasets.data(\"datasets\",\"iris\");\n",
      "features = matrix(iris[:,2:5]);\n",
      "labels = matrix(iris)[:,6];\n",
      "sz,ft = size(features);\n",
      "train = randbool(sz)\n",
      "test = !train;"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 112
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "K-means Clustering"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nc=3\n",
      "km=Clustering.kmeans(features',nc);\n",
      "centers=km.centers;"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Iters               objv        objv-change | affected \n",
        "-------------------------------------------------------------\n",
        "      1       9.215602e+01      -5.825398e+01 |        2\n",
        "      2       8.368890e+01      -8.467122e+00 |        3\n",
        "      3       7.986398e+01      -3.824915e+00 |        2\n",
        "      4       7.919714e+01      -6.668418e-01 |        2\n",
        "      5       7.885144e+01      -3.457012e-01 |        0\n",
        "      6       7.885144e+01       0.000000e+00 |        0\n",
        "K-means converged with 6 iterations (objv = 78.85144142614597)\n"
       ]
      }
     ],
     "prompt_number": 112
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "km.centers"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 113,
       "text": [
        "4x3 Array{Float64,2}:\n",
        " 5.90161  5.006  6.85   \n",
        " 2.74839  3.428  3.07368\n",
        " 4.39355  1.462  5.74211\n",
        " 1.43387  0.246  2.07105"
       ]
      }
     ],
     "prompt_number": 113
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "SVM"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Y = [species == \"setosa\" ? 1.0 : -1.0 for species in iris[:, \"Species\"]];\n",
      "X=features'\n",
      "model=SVM.svm(X[:,train],Y[train])\n",
      "prediction=SVM.predict(model, X[:,test])\n",
      "DecisionTree.confusion_matrix(prediction,Y[test])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 114,
       "text": [
        "Classes:  [-1.0,1.0]\n",
        "Matrix:   2x2 Array{Int64,2}:\n",
        " 50   0\n",
        "  0  22\n",
        "Accuracy: 1.0\n",
        "Kappa:    1.0"
       ]
      }
     ],
     "prompt_number": 114
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Random Forest"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "modelrf=DecisionTree.build_forest(labels[train],features[train,:],4,30);\n",
      "predrf=DecisionTree.apply_forest(modelrf,features[test,:]);\n",
      "println(DecisionTree.confusion_matrix(labels[test],predrf));"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Classes:  {"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\"setosa\",\"versicolor\",\"virginica\"}\n",
        "Matrix:   3x3 Array{Int64,2}:\n",
        " 22   0   0\n",
        "  1  24   2\n",
        "  0   3  20\n",
        "Accuracy: 0.9166666666666666\n",
        "Kappa:    0.8745280278826603\n"
       ]
      }
     ],
     "prompt_number": 114
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "accuracyrf = DecisionTree.nfoldCV_forest(labels, features, 4, 30, 3);"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Fold "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1\n",
        "Classes:  {\"setosa\",\"versicolor\",\"virginica\"}\n",
        "Matrix:   3x3 Array{Int64,2}:\n",
        " 17   0   0\n",
        "  0  15   0\n",
        "  0   1  17\n",
        "Accuracy: 0.98\n",
        "Kappa:    0.96996996996997\n",
        "\n",
        "Fold "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2\n",
        "Classes:  {\"setosa\",\"versicolor\",\"virginica\"}\n",
        "Matrix:   3x3 Array{Int64,2}:\n",
        " 16   0   0\n",
        "  0  16   1\n",
        "  0   3  14\n",
        "Accuracy: 0.92\n",
        "Kappa:    0.879951980792317\n",
        "\n",
        "Fold "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "3\n",
        "Classes:  {\"setosa\",\"versicolor\",\"virginica\"}\n",
        "Matrix:   3x3 Array{Int64,2}:\n",
        " 17   0   0\n",
        "  0  16   2\n",
        "  0   1  14\n",
        "Accuracy: 0.94\n",
        "Kappa:    0.9099099099099098\n",
        "\n",
        "Mean Accuracy: 0.9466666666666667\n"
       ]
      }
     ],
     "prompt_number": 114
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Adaptive-Boosted Tree (Adaboost)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "modelad,coeffs=DecisionTree.build_adaboost_stumps(labels[train],features[train,:],50);\n",
      "predad=DecisionTree.apply_forest(modelad,features[test,:]);\n",
      "println(DecisionTree.confusion_matrix(labels[test],predad));"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Classes:  "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{\"setosa\",\"versicolor\",\"virginica\"}\n",
        "Matrix:   3x3 Array{Int64,2}:\n",
        " 22  0   0\n",
        "  1  8  18\n",
        "  0  0  23\n",
        "Accuracy: 0.7361111111111112\n",
        "Kappa:    0.6112531969309464\n"
       ]
      }
     ],
     "prompt_number": 114
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "accuracyad = DecisionTree.nfoldCV_stumps(labels, features, 50, 3);"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Fold "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1\n",
        "Classes:  {\"setosa\",\"versicolor\",\"virginica\"}\n",
        "Matrix:   3x3 Array{Int64,2}:\n",
        " 0  22   0\n",
        " 0  18   0\n",
        " 0   0  10\n",
        "Accuracy: 0.56\n",
        "Kappa:    0.34523809523809534\n",
        "\n",
        "Fold "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2\n",
        "Classes:  {\"setosa\",\"versicolor\",\"virginica\"}\n",
        "Matrix:   3x3 Array{Int64,2}:\n",
        " 13  0   0\n",
        "  0  5  13\n",
        "  0  0  19\n",
        "Accuracy: 0.74\n",
        "Kappa:    0.6019595835884874\n",
        "\n",
        "Fold "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "3\n",
        "Classes:  {\"setosa\",\"versicolor\",\"virginica\"}\n",
        "Matrix:   3x3 Array{Int64,2}:\n",
        " 15   0   0\n",
        "  0  10   4\n",
        "  0   1  20\n",
        "Accuracy: 0.9\n",
        "Kappa:    0.8453927025355595\n",
        "\n",
        "Mean Accuracy: 0.7333333333333334\n"
       ]
      }
     ],
     "prompt_number": 114
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Pruned Tree"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "modelpt=DecisionTree.build_tree(labels[train],features[train,:])\n",
      "predpt=DecisionTree.apply_tree(modelpt,features[test,:]);\n",
      "println(DecisionTree.confusion_matrix(labels[test],predpt));"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Classes:  {\"setosa\",\"versicolor\",\"virginica\"}\n",
        "Matrix:   3x3 Array{Int64,2}:\n",
        " 22   0   0\n",
        "  1  25   1\n",
        "  0   3  20\n",
        "Accuracy: 0.9305555555555556\n",
        "Kappa:    0.8953184065135215\n"
       ]
      }
     ],
     "prompt_number": 114
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "accuracypt = DecisionTree.nfoldCV_tree(labels, features, 0.9, 3);"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Fold 1\n",
        "Classes:  {\"setosa\",\"versicolor\",\"virginica\"}\n",
        "Matrix:   3x3 Array{Int64,2}:\n",
        " "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "20   0   0\n",
        "  0  14   1\n",
        "  0   0  15\n",
        "Accuracy: 0.98\n",
        "Kappa:    0.9696969696969696\n",
        "\n",
        "Fold 2\n",
        "Classes:  {\"setosa\",\"versicolor\",\"virginica\"}\n",
        "Matrix:   3x3 Array{Int64,2}:\n",
        " 15   0   0\n",
        "  0  15   0\n",
        "  0   1  19\n",
        "Accuracy: 0.98\n",
        "Kappa:    0.9697885196374622\n",
        "\n",
        "Fold 3\n",
        "Classes:  {\"setosa\",\"versicolor\",\"virginica\"}\n",
        "Matrix:   3x3 Array{Int64,2}:\n",
        " 15   0   0\n",
        "  3  15   2\n",
        "  0   1  14\n",
        "Accuracy: 0.88\n",
        "Kappa:    0.8203592814371259\n",
        "\n",
        "Mean Accuracy: 0.9466666666666667\n"
       ]
      }
     ],
     "prompt_number": 114
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Neural Network"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# https://github.com/nwenzel/Julia_Neural_Network\n",
      "# Code by Nathan Wenzel\n",
      "\n",
      "function sigmoid(z)\n",
      "  # sigmoid is a basic sigmoid function returning values from 0-1\n",
      "  1. / ( 1. + 1e.^(-z) )\n",
      "end\n",
      "\n",
      "function sigmoidGradient(z)\n",
      "  sigmoid(z) .* ( 1 - sigmoid(z) )\n",
      "end\n",
      "\n",
      "function initialize_theta(input_unit_count, output_class_count, hidden_unit_length_list)\n",
      "  #\n",
      "  #initialize_theta creates architecture of neural network\n",
      "  #    \n",
      "  #Parameters:\n",
      "  #  hidden_unit_length_list - Array of hidden layer units\n",
      "  #  input_unit_count - integer, number of input units (features)\n",
      "  #  output_class_count - integer, number of output classes\n",
      "  #\n",
      "  #Returns:\n",
      "  #  \n",
      "  #Array of theta arrays randomly initialized to from -.5 to .5\n",
      "  #\n",
      "  \n",
      "  if length( hidden_unit_length_list ) == 0\n",
      "    hidden_unit_length_list = [2]\n",
      "  end\n",
      "  \n",
      "  unit_count_list = [input_unit_count]\n",
      "  unit_count_list = [unit_count_list, hidden_unit_length_list]\n",
      "  unit_count_list = [unit_count_list, output_class_count]\n",
      "  layers = length(unit_count_list)\n",
      "  \n",
      "  Theta_L = [ rand( unit_count_list[i], unit_count_list[i-1]+1 ) - .5 for i = 2:layers]\n",
      "\n",
      "end\n",
      "\n",
      "function print_theta(Theta_L)\n",
      "  # print_theta() is a helper function that prints Theta_L and architecture info\n",
      "  # It does not actually \"do\" anything except print to stdout\n",
      "\n",
      "  T = length(Theta_L)\n",
      "\n",
      "  println()\n",
      "  println( \"NN ARCHITECTURE\" )\n",
      "  println( \"$(T+1) Layers ($(T-1) Hidden)\" )\n",
      "  println( \"$T Thetas\" )\n",
      "  println( \"$(size(Theta_L[1],2)-1) Input Features\" )\n",
      "  println( \"$(size(Theta_L[end], 1)) Output Classes\" )\n",
      "  println()\n",
      "    \n",
      "  println( \"Units per layer (excl. bias unit)\" )\n",
      "  for t = 1:T\n",
      "    if t == 1\n",
      "      println( \" - Input: $(size(Theta_L[t],2)-1) Units\" )\n",
      "    end\n",
      "    if t < T\n",
      "      println( \" - Hidden $t: $(size(Theta_L[t],1)) Units\" )\n",
      "    else\n",
      "      println( \" - Output: $(size(Theta_L[t],1)) Units\" )\n",
      "    end\n",
      "  end\n",
      "  println()\n",
      "\n",
      "  println( \"Theta Shapes\" )\n",
      "  for l = 1:T\n",
      "    println( \"Theta $l: $(size(Theta_L[l]))\" )\n",
      "  end\n",
      "  println()\n",
      "  \n",
      "  println( \"Theta Values\" )\n",
      "  for t= 1:T\n",
      "    println( \"Theta $t:\"  )\n",
      "    println ( Theta_L[t])\n",
      "  end\n",
      "  println()\n",
      "\n",
      "end\n",
      "\n",
      "function nn_cost(Y, Y_pred)\n",
      "  #\n",
      "  # nn_cost implements cost function for array inputs Y and Y_pred\n",
      "  #  \n",
      "  # y is array of n_observations by n_classes\n",
      "  # Y_pred is array with same dimensions as Y of predicted y values\n",
      "  #\n",
      "  if size(Y) != size(Y_pred)\n",
      "    if size(Y,1) != size(Y_pred,1)\n",
      "      error(\"Wrong number of predictions\", \"$(size(Y,1)) Actual Values. $(size(Y_pred,1)) Predicted Values. \")\n",
      "    else\n",
      "      error(\"Wrong number of prediction classes\", \"$(size(Y,2)) Actual Classes. $(size(Y_pred,2)) Predicted Classes. \")\n",
      "    end\n",
      "  end\n",
      "    \n",
      "  n_observations = size(Y,1)\n",
      "  \n",
      "  # Cost Function\n",
      "  J = (-1.0 / n_observations ) * sum((Y .* log(Y_pred)) + ((1-Y) .* log(1-Y_pred)))\n",
      "  \n",
      "  J\n",
      "\n",
      "end\n",
      "\n",
      "\n",
      "\n",
      "function nn_predict(X, Theta_L)\n",
      "  #\n",
      "  # nn_predict calculates activations for all layers given X and thetas in Theta_L\n",
      "  # return all inputs and activations for all layers for use in backprop\n",
      "  #\n",
      "  # Parameters\n",
      "  #  X is matrix of input features dimensions n_observations by n_features\n",
      "  #  Theta_L is a 3D array where first element corresponds to the layer number, second is unit at layer+1, third is unit in layer\n",
      "  #\n",
      "  # Returns\n",
      "  #  a_N - 1D Array of activation 2D arrays for each layer: Input (1), Hidden (2 to T), and Output (T+1)\n",
      "  #  a_Z - 1D Array of input 2D arrays to compute activations for all non-bias units\n",
      "  #  a_N[end] - 2D Array of predicted Y values with dimensions n_observations by n_classes\n",
      "  #\n",
      "\n",
      "  a_N = {}\n",
      "  z_N = {}\n",
      "\n",
      "  m = size(X,1)\n",
      "  T = length(Theta_L)\n",
      "    \n",
      "  # Input Layer inputs\n",
      "  push!(a_N, X) \t\t\t# List of activations including bias unit for non-output layers\n",
      "  push!(z_N, zeros(1,1)) \t# add filler Z layer to align keys/indexes for a, z, and Theta\n",
      "\n",
      "  # Loop through each Theta_List theta\n",
      "  # t is index of Theta for calculating layer t+1 from layer t\n",
      "  for t=1:T\n",
      "    # Reshape 1D Array into 2D Array\n",
      "    if ndims(a_N[t]) == 1\n",
      "      a_N[t] = reshape(a_N[t], 1, size(a_N[t],1))\n",
      "    end\n",
      "\n",
      "    # Add bias unit\n",
      "    a_N[t] = [ ones(size(a_N[t],1), 1)  a_N[t] ]\n",
      "      \n",
      "    # Calculate and Append new z and a arrays to z_N and a_N lists\n",
      "    push!(z_N, a_N[t] * Theta_L[t]') #'\n",
      "    push!(a_N, sigmoid(z_N[t+1]))\n",
      "  end\n",
      "  \n",
      "  z_N, a_N, a_N[end]\n",
      "\n",
      "end\n",
      "\n",
      "\n",
      "function back_prop(X_train, Y_train, Theta_L, lmda)\n",
      "  #\n",
      "  # Parameters\n",
      "  #  X_train - Array of feature inputs with dimensions n_observations by n_features\n",
      "  #  Y_train - Array of class outputs with dimensions n_observations by n_classes\n",
      "  #  Theta_L is a 1D array of Theta values where 1D element is the layer number, the 2D elements are unit in layer+1 and unit in layer\n",
      "  #  lmda - Float64 - lambda term for regularization\n",
      "  #  \n",
      "  # Returns\n",
      "  #  Y_pred as array of predicted Y values from nn_predict()\n",
      "  #  Theta_Gradient_L as 1D array of 2D Theta Gradient arrays\n",
      "  #\n",
      "\n",
      "  n_observations = size(X_train,1)\n",
      "  \n",
      "  T = length(Theta_L)\n",
      "\n",
      "  # Create Modified copy of the Theta_L for Regularization with Coefficient for bias unit set to 0 so that bias unit is not regularized\n",
      "  # Create variable to accumulate error caused by each Theta_L term in layer a_N[n+1]\n",
      "  Theta_Gradient_L = {}\n",
      "  regTheta = {}\n",
      "  for i=1:T\n",
      "    push!(regTheta, [zeros(size(Theta_L[i],1),1) Theta_L[i][:,2:]])\n",
      "    push!(Theta_Gradient_L, zeros(size(Theta_L[i])))\n",
      "  end\n",
      "\n",
      "\n",
      "  # Forward Pass\n",
      "  z_N, a_N, Y_pred = nn_predict(X_train, Theta_L)\n",
      "\n",
      "  # Backprop Error Accumulator\n",
      "  delta_N = {}\n",
      "  for t=1:T\n",
      "    push!(delta_N, {})\n",
      "  end\n",
      "    \n",
      "  # Error for Output layer is predicted value - Y training value\n",
      "  delta = Y_pred - Y_train\n",
      "  if ndims(delta) == 1\n",
      "    delta = reshape(delta, 1, length(delta) )\n",
      "  end\n",
      "\n",
      "  # Loop backwards through Thetas to apply Error to prior Layer (except input layer)\n",
      "  # Finish at T-2 because start at 0, output layer is done outside, the loop and input has no error\n",
      "\n",
      "  # Output Error\n",
      "  delta_N[T] = delta\n",
      "\n",
      "  # Hidden Layers Error    \n",
      "  for t=0:T-2\n",
      "    delta = (delta * Theta_L[T-t][:,2:]) .* sigmoidGradient(z_N[T-t])\n",
      "    delta_N[T-t-1] = delta\n",
      "  end\n",
      "    \n",
      "  # Calculate error gradients (no error in input layer)\n",
      "  # t is the Theta from layer t to layer t+1\n",
      "  for t=1:T\n",
      "    Theta_Gradient_L[t] = Theta_Gradient_L[t] + delta_N[t]' * a_N[t] #'\n",
      "  end\n",
      "\n",
      "  # Average Error + regularization penalty  \n",
      "  for t=1:T\n",
      "    Theta_Gradient_L[t] = Theta_Gradient_L[t] * (1.0/n_observations) + (lmda * regTheta[t])\n",
      "  end\n",
      "  \n",
      "  Y_pred, Theta_Gradient_L\n",
      "\n",
      "end\n",
      "\n",
      "\n",
      "\n",
      "function fit(X_train, Y_train, Theta_L, lmda, epochs)\n",
      "  #\n",
      "  #fit() calls the training back_prop function for the given number of cycles\n",
      "  #tracks error and error improvement rates\n",
      "  #  \n",
      "  #Parameters:\n",
      "  #  X_train - Array of training data with dimension n_observations by n_features\n",
      "  #  Y_train - Array of training classes with dimension n_observations by n_classes\n",
      "  #  Theta_L - 1D array of theta 2d arrays where each theta has dimensions n_units[layer+1] by n_units[layer]+1\n",
      "  #  epochs -  integer of number of times to update Theta_L\n",
      "  #  \n",
      "  #Returns\n",
      "  #  Theta_L - 1D array of Theta arrays\n",
      "  #  J_List - Array (length = epochs) of result of cost function for each iteration\n",
      "\n",
      "  J_list = zeros( epochs )\n",
      "\n",
      "  for i=1:epochs\n",
      "    # Back prop to get Y_pred and Theta gradient\n",
      "    Y_pred, Theta_grad = back_prop(X_train, Y_train, Theta_L, lmda)\n",
      "    # Record cost\n",
      "    J_list[i] = nn_cost(Y_train, Y_pred)\n",
      "    # Update Theta using Learning Rate * Theta Gradient\n",
      "    for t=1:length(Theta_L)\n",
      "      # Start with a large learning rate; need to update this to be more intelligent than simply looking at iteration count\n",
      "      # Need to update to change learning rate based on progress of cost function\n",
      "      if i < 100\n",
      "        learning_rate = 5.0        \n",
      "      else\n",
      "        learning_rate = 1.0\n",
      "      end\n",
      "      Theta_L[t] = Theta_L[t] - ( learning_rate * Theta_grad[t] )\n",
      "    end\n",
      "    #println(\"Cost $i: $(J_list[i])\")\n",
      "  end\n",
      "\n",
      "  Theta_L, J_list\n",
      "\n",
      "end\n",
      "\n",
      "\n",
      "function XOR_test(hidden_unit_length_list, epochs)\n",
      "  #\n",
      "  #XOR_test is a simple test of the nn printing the predicted value to std out\n",
      "  #Trains on a sample XOR data set\n",
      "  #Predicts a single value\n",
      "  #Accepts an option parameter to set architecture of hidden layers\n",
      "  #\n",
      "  \n",
      "  \n",
      "  println( \"Training Data: X & Y\")\n",
      "\n",
      "  # Training Data\n",
      "  X_train = [1 1; 1 0; 0 1; 0 0]\t# Training Input Data\n",
      "  Y_train = [0 1; 1 0; 1 0; 0 1] \t\t\t# Training Classes\n",
      "  println( X_train )\n",
      "  println( Y_train )\n",
      "  \n",
      "  # Hidden layer architecture\n",
      "  hidden_layer_architecture = hidden_unit_length_list\n",
      "\n",
      "  # Regularization Term\n",
      "  lmda = 1e-5\n",
      "\n",
      "  # Initialize Theta based on selected architecture\n",
      "  Theta_L = initialize_theta(size(X_train,2), size(Y_train,2), hidden_layer_architecture)\n",
      "\n",
      "  \n",
      "  # Fit\n",
      "  Theta_L, J_list = fit(X_train, Y_train, Theta_L, lmda, epochs)\n",
      "  \n",
      "  # Print Architecture\n",
      "  print_theta(Theta_L)\n",
      "  \n",
      "  # Print Cost\n",
      "  println(\"Cost Function Applied to Training Data: $(J_list[end])\")\n",
      "\n",
      "  # Predict\n",
      "  X_new = [1 0;0 1;1 1;0 0]\n",
      "  println( \"Given X:\")\n",
      "  println(\"$X_new\")\n",
      "  z_N, a_N, Y_pred = nn_predict(X_new, Theta_L)\n",
      "  println( \"Predicted Y:\") \n",
      "  println(\"$(round(Y_pred,3))\")\n",
      "\n",
      "  Y_pred\n",
      "\n",
      "end\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 8,
       "text": [
        "XOR_test (generic function with 1 method)"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Y_pred = XOR_test([2], 5000)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Training Data: X & Y\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1\t1\n",
        "1\t0\n",
        "0\t1\n",
        "0\t0\n",
        "\n",
        "0\t1\n",
        "1\t0\n",
        "1\t0\n",
        "0\t1\n",
        "\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "NN ARCHITECTURE\n",
        "3 Layers (1 Hidden)\n",
        "2 Thetas\n",
        "2 Input Features\n",
        "2 Output Classes\n",
        "\n",
        "Units per layer (excl. bias unit)\n",
        " - Input: 2 Units\n",
        " - Hidden 1: 2 Units\n",
        " - Output: 2 Units\n",
        "\n",
        "Theta Shapes\n",
        "Theta 1: (2,3)\n",
        "Theta 2: (2,3)\n",
        "\n",
        "Theta Values\n",
        "Theta 1:\n",
        "-4.244057658582526\t8.011119225793868\t-8.218268440922987\n",
        "3.9453941972708795\t8.156949365387408\t-7.86130314531543\n",
        "\n",
        "Theta 2:\n",
        "5.735531100620542\t12.358587250630872\t-11.947865946940489\n",
        "-5.7395079853749005\t-12.366440373984625\t11.955769589062232\n",
        "\n",
        "\n",
        "Cost Function Applied to Training Data: 0.006301094016920786\n",
        "Given X:\n",
        "1\t0\n",
        "0\t1\n",
        "1\t1\n",
        "0\t0\n",
        "\n",
        "Predicted Y:\n",
        ".997\t.003\n",
        ".996\t.004\n",
        ".003\t.997\n",
        ".003\t.997\n",
        "\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 14,
       "text": [
        "4x2 Array{Float64,2}:\n",
        " 0.997177    0.0028127 \n",
        " 0.995939    0.00404581\n",
        " 0.00273109  0.997279  \n",
        " 0.00298615  0.997025  "
       ]
      }
     ],
     "prompt_number": 14
    }
   ],
   "metadata": {}
  }
 ]
}